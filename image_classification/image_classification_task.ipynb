{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cffb2e8",
   "language": "python",
   "display_name": "PyCharm (ProphetAI)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "colab": {
   "name": "Copy of Transfer_Learning.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "9Od8d_50kdE1",
    "colab_type": "code",
    "outputId": "55077fc8-008b-4401-d18a-4877034ac759",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__ # 2.0.0"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y7n_lRX0kA5H",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VJRx23bxkA5N",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    " \n",
    "SEED = 777\n",
    "tf.random.set_seed(SEED)  \n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "\n",
    "## recommended gpu settings by Lattari ##\n",
    "\n",
    "# Set GPU memory growth\n",
    "# Allows to only as much GPU memory as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MAL8QMTMkhsc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Batch size\n",
    "bs =  8\n",
    "\n",
    "# img shape\n",
    "\n",
    "img_h = 320\n",
    "img_w = 320"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RS--518HkA5R",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "if apply_data_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(rotation_range=10, \n",
    "                                        width_shift_range=10,\n",
    "                                        validation_split=0.2,\n",
    "                                        height_shift_range=10,\n",
    "                                        zoom_range=0.3,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True,\n",
    "                                        fill_mode='constant',\n",
    "                                        cval=0,\n",
    "                                        rescale=1./255)\n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create validation and test ImageDataGenerator objects\n",
    "valid_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cJwrVEkikA5W",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Create generators to read images from dataset directory\n",
    "# -------------------------------------------------------\n",
    "dataset_dir = os.path.join('./', 'Classification_Dataset')\n",
    "\n",
    "num_classes=20\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GODBCI6NxVe6",
    "colab_type": "code",
    "outputId": "84e6594b-d113-4848-8a30-30238cc59322",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "source": [
    "classes = ['owl',\n",
    "'galaxy' ,\n",
    "'lightning' ,\n",
    "'wine-bottle' ,\n",
    "'t-shirt' ,\n",
    "'waterfall' ,\n",
    "'sword' ,\n",
    "'school-bus' ,\n",
    "'calculator' ,\n",
    "'sheet-music' ,\n",
    "'airplanes' ,\n",
    "'lightbulb',\n",
    "'skyscraper',\n",
    "'mountain-bike',\n",
    "'fireworks',\n",
    "'computer-monitor' ,\n",
    "'bear',\n",
    "'grand-piano', \n",
    "'kangaroo',\n",
    "'laptop' ]        \n",
    "\n",
    "train_gen = train_data_gen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'training'),\n",
    "    target_size = (320, 320),\n",
    "    batch_size = 8,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode='rgb',\n",
    "    classes=classes, \n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "valid_gen = train_data_gen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'test'),\n",
    "    target_size = (320, 320),\n",
    "    batch_size = 8,\n",
    "    color_mode='rgb',\n",
    "    classes=classes,\n",
    "    class_mode='categorical',\n",
    "    subset=\"validation\",\n",
    "    shuffle=False,\n",
    "    seed=SEED)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Found 1247 images belonging to 20 classes.\n",
      "Found 307 images belonging to 20 classes.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v9UxS2NIzA2h",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "# ----------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "# Repeat\n",
    "valid_dataset = valid_dataset.repeat()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuQ9p5N9kA5f",
    "colab_type": "text"
   },
   "source": [
    "# Transfer Learning\n",
    "## Here we are using InceptionV3 implementation provided by keras"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1foiZKVhos7W",
    "colab_type": "code",
    "outputId": "9841d2a9-14fb-4fa3-babd-4d96ee758418",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    }
   },
   "source": [
    "mn = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(320, 320, 3))"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 8s 0us/step\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gN3YLhUIOgDh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "mn.summary()\n",
    "for layer in mn.layers:\n",
    "    print(layer, layer.trainable)\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hHJxxM1PpMin",
    "colab_type": "code",
    "outputId": "b95235a3-25d2-4f03-ee7b-2fdd01251e0a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "len(mn.layers)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfyQEhptm2Z9",
    "colab_type": "text"
   },
   "source": [
    "Model Creation: \n",
    "Here tried multiple finetunings, but didn't get as much as freezing until 311 layer (so last layer) "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "haWVQkg5kA5n",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# The Model\n",
    "# ------------\n",
    "\n",
    "finetuning = True\n",
    "\n",
    "if finetuning:\n",
    "    freeze_until = 311 # layer from which we want to fine-tune\n",
    "    \n",
    "    for layer in mn.layers[:freeze_until]:\n",
    "        layer.trainable = False\n",
    "else:\n",
    "    mn.trainable = False\n",
    "    \n",
    "model = tf.keras.Sequential()\n",
    "model.add(mn)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# Visualize created model as a table\n",
    "model.summary()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OTBwJ93kA5p",
    "colab_type": "text"
   },
   "source": [
    "## Prepare the model for training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fjMSol0bkA5q",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Optimization parameters\n",
    "# -----------------------\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdH6sn93kA5t",
    "colab_type": "text"
   },
   "source": [
    "## Training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "id": "1qj2LVnBkA5u",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "exps_dir = os.path.join('./', 'inceptionV3_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN_inceptionV3_no_fine_tuning'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "# if not os.path.exists(ckpt_dir):\n",
    "#     os.makedirs(ckpt_dir)\n",
    "\n",
    "# ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "#                                                  save_weights_only=True)  # False to save the model directly\n",
    "# callbacks.append(ckpt_callback)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=100,  \n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen), \n",
    "          callbacks=callbacks)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g-iZyb05YQ4o",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "\n",
    "def load(filename):\n",
    "   np_image = Image.open(filename)\n",
    "   np_image = np.array(np_image).astype('float32')/255\n",
    "   np_image = transform.resize(np_image, (320, 320, 3))\n",
    "   np_image = np.expand_dims(np_image, axis=0)\n",
    "   return np_image\n",
    "\n",
    "dict_img_pred = {}\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "for i in tqdm(os.listdir(os.path.join(dataset_dir,'test'))):\n",
    "  \n",
    "  image = load(os.path.join(dataset_dir,'test',i))\n",
    "  out_softmax = model.predict(image)\n",
    "  predicted_class = tf.argmax(out_softmax, 1)\n",
    "  dict_img_pred[i] = predicted_class.numpy()[0]\n",
    "\n",
    "# finally creating submission\n",
    "create_csv(dict_img_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}